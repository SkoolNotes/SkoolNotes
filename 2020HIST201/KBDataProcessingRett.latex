\documentclass[
]{article}

\setlength\parindent{0pt}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[normalem]{ulem}

\usepackage{cancel}

\usepackage{ifthen}
\usepackage{trimspaces}

\usepackage{graphicx}
\usepackage{xesearch}
\usepackage[dvipsnames]{xcolor}

\usepackage{enumitem}
\setlistdepth{9}

\setlist[itemize,1]{label=\textbullet}
\setlist[itemize,2]{label=\textbullet}
\setlist[itemize,3]{label=\textbullet}
\setlist[itemize,4]{label=\textbullet}
\setlist[itemize,5]{label=\textbullet}
\setlist[itemize,6]{label=\textbullet}
\setlist[itemize,7]{label=\textbullet}
\setlist[itemize,8]{label=\textbullet}
\setlist[itemize,9]{label=\textbullet}

\renewlist{itemize}{itemize}{9}

\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother


\UndoBoundary{[, ], \_}
\SearchList{startbrac}{}{*[?}
\SearchList{endbrac}{}{*]?}
\SearchList{kbtag}{\color{ForestGreen}{\href{http://taproot.shabang.cf/relay?request=#1}{\tiny\textulf{[[}\textbf{#1}\textulf{]]}}}\color{black}}{*KB?}



% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\graphicspath{ {./} }

\usepackage{titlesec}
\usepackage{titling}
\usepackage{makecell}
\usepackage{bookmark}

\usepackage{float}
\let\origfigure\figure
\let\endorigfigure\endfigure
\renewenvironment{figure}[1][2] {
    \expandafter\origfigure\expandafter[H]
} {
    \endorigfigure
}

\usepackage{mathspec}
%\setmainfont[
%   ItalicFont     = HelveticaNeue-Italic,
%   BoldFont       = HelveticaNeue-Bold,
%   BoldItalicFont = HelveticaNeue-BoldItalic]{HelveticaNeue}
%\newfontfamily\NHLight[
%   ItalicFont     = HelveticaNeue-LightItalic,
%   BoldFont       = HelveticaNeue-UltraLight,
%   BoldItalicFont = HelveticaNeue-UltraLightItalic]{HelveticaNeue-Light}
\setmainfont[
   ItalicFont     = Iosevka-Aile-Italic,
   BoldFont       = Iosevka-Aile-Bold,
   BoldItalicFont = Iosevka-Aile-Bold-Italic]{Iosevka}
\newfontfamily\NHLight[
   ItalicFont     = Iosevka-Aile-Light-Italic,
   BoldFont       = Iosevka-Aile-Light,
   BoldItalicFont = Iosevka-Aile-Light-Italic]{Iosevka-Light}

\newcommand\textrmlf[1]{{\NHLight#1}}
\newcommand\textitlf[1]{{\NHLight\itshape#1}}
\let\textbflf\textrm
\newcommand\textulf[1]{{\NHLight\bfseries#1}}
\newcommand\textuitlf[1]{{\NHLight\bfseries\itshape#1}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



\usepackage[margin=1in]{geometry}

\usepackage{fancyhdr}
\usepackage{hyperref}

\usepackage{longtable,booktabs}
\usepackage{caption}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}


\newcommand{\thecourse}{ ML301 }
\newcommand{\thelesson}{ Data Processing Assignment }

\title{\textbf{\thecourse}\thelesson}

\pagestyle{fancy}

\fancyfoot{}

\makeatletter
\trim@spaces@in \thecourse
\trim@spaces@in \thelesson
\makeatother
\lhead{\textbf{\thecourse} \thelesson}
%\rhead{\textrmlf{Compiled} \today \textrmlf{\ ({\#}6143)}}    % original
%\rhead{\textrmlf{Compiled }\#6143\textrmlf{ on} \today }      % old date
\rhead{\textrmlf{Compiled }\#6143\textrmlf{ on} \today}       % new date
\lfoot{Huxley \(\cdot\) \textbf{2020-2021}}
\rfoot{\textrmlf{Page} \thepage}


\titleformat{\section}
{\Large}
{\textrmlf{\thesection} {|}}
{0.3em}
{\textbf}


\titleformat{\subsection}
{\large}
{\textrmlf{\thesubsection} {|}}
{0.2em}
{\textbf}

\titleformat{\subsubsection}
{\large}
{\textrmlf{\thesubsubsection} {|}}
{0.1em}
{\textbf}

\setlength{\parskip}{0.45em}

\newcounter{definitionct}
\newcommand{\definition}[3][]{
    \stepcounter{definitionct}
    \begin{center}
        Definition \arabic{definitionct} \(\cdot\) [ \textbf{#2} \textrmlf{#3} ]
        \ifthenelse{ \equal{#1}{} }
            {}
            {\\ \textrmlf{#1}}
    \end{center}
}

\begin{document}

% DID YOU SET SPELL????
\textbf{Source}:\thinspace 
{\href{http://taproot.shabang.cf/relay?request=}{\tiny\textulf{[[}\textbf{}\textulf{]]}}}\thinspace

\#ret

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{prompt}{%
\subsection{Prompt:}\label{prompt}}

\begin{verbatim}
For each of the scenarios below, answer the following questions. You do not have to explain your answers other than to explain where your targets would come from (Are they in the dataset already? Do you need to create them by hand?) and how you would make any non-numerical inputs numerical, if required by the algorithm you choose.

1. What type of machine learning problem (regression, classification, clustering) do you think this is?
2. If this is a supervised problem, what will you use as your targets (aka labels) and how will you get them? If this is an unsupervised problem, just write "none".
3. What processing do you need to do to your input data? (How will you handle non-numerical inputs? Do you plan to do any scaling? etc.)
4. What type(s) of model(s) would you try? Remember to start with the simplest thing that might work! The types of models we've talked about are linear regression, decision trees, random forest, logistic regression, naive bayes, K-means, DBSCAN, and fully connected neural networks.
5. What validation metric(s) would you use to decide how well you're doing?
6. What ethical challenges do the data collection, creation, and/or use of this model create? If you feel there aren’t any, just say “None”.


Scenarios:

1. You are playing fantasy football and want to predict how many points each player will score next season. You have their stats, including points scored, from last season, plus their height, weight, and position -- except for players new to the league, for whom you don't have last year's stats, only height, weight, and position.
2. You have customer reviews, each one of which has a rating from 1 (worst) to 10 (best) and some text. The reviews vary greatly in their length. You would like to use this to write a model that can predict if text is positive, negative, or neutral, along with a probability score (e.g., 68% likely to be positive, 30% neutral, 2% negative).
3. You have data from a movie streaming service that consists of lists of movies that each user has watched as well as information about each movie: title, names of the stars, genre, and length. You would like to make a model that will help you decide what movies to recommend to users.
4. You want to predict whether a random stranger owns a cat, a dog, or neither, based on things that they like on Facebook. You decide to train your model on your friends, and write a program to collect all of their public Likes. 
5. You want a model to predict the number of deer that will be born in a breeding season. You have a large amount of historical data, and each row consists of the following information for the breeding season of a particular area and species:
        number of fawns born
        the genus and species
        number of does sighted during the mating season
        vegetation quality during the mating season ("low", "average", or "high")
\end{verbatim}

\hypertarget{scenarios}{%
\subsection{Scenarios:}\label{scenarios}}

\begin{itemize}
\tightlist
\item
  Football

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Note: Since we only have one season of point values, and hence
    cannot see cross season change in point values, the old season
    players will be used as training data.
  \item
    Regression
  \item
    Label: Point value
  \item
    One Hot Encoding, 0-1 normalization
  \item
    Linear Regression or Neural Networks
  \item
    RMSE
  \item
    None
  \end{enumerate}
\item
  Customer Reviews

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Classification
  \item
    Positive, Negative, Neutral
  \item
    Some form of text processing -- BOW, TFIDF, word vectors, ect.
  \item
    Out of the models we have learned, Naive Bayes.
  \item
    F score
  \item
    Could misrepresent reviews and allow for automation
  \end{enumerate}
\item
  Movie Recommendations

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Classification
  \item
    Semi-supervised.
  \item
    One Hot Encoding and BOW or TFIDF
  \item
    Random forest? NN?
  \item
    Click rate or watch time, depending on goal.
  \item
    Ethics crumble in the face of capitalism. We gotta get our clients
    the right recommendations!
  \end{enumerate}
\item
  Facebook Pet

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Classification
  \item
    Supervised: Dog, Cat, Neither
  \item
    WPIE type system.
  \item
    NN
  \item
    F score\\
  \item
    Collection of likes is invasive. Categorizing of people is also
    problematic, as is trying to determine private info.
  \end{enumerate}
\item
  Deer Born

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Regression
  \item
    Supervised: Number of deer
  \item
    One Hot
  \item
    Linear regression, NN
  \item
    RMSE
  \item
    None
  \end{enumerate}
\end{itemize}

\hypertarget{comment-response}{%
\subsection{Comment Response}\label{comment-response}}

\begin{itemize}
\tightlist
\item
  2b. How do you convert from the 1-10 rating scale to
  positive/negative/neutral?

  \begin{itemize}
  \tightlist
  \item
    You would have to pick ranges that define what is
    positive/negative/neutral
  \end{itemize}
\item
  2c. Given that the reviews vary greatly in their length, is one of
  these preferred over the other?

  \begin{itemize}
  \tightlist
  \item
    BOW doesn't work well when length varies. TFIDF, however, does.
  \end{itemize}
\item
  2e. Why not accuracy, precision, or recall?

  \begin{itemize}
  \tightlist
  \item
    Those would all work as well. I just decided to list one possible
    validation metric as opposed to all of them.
  \end{itemize}
\item
  3a. This could work, but I think you will find this problem more
  straightforward as a different kind of problem.

  \begin{itemize}
  \tightlist
  \item
    I guess this problem could be done as a clustering problem,
    representing each movie as a location in a multidimensional space
    then placing users in the space and clustering.
  \end{itemize}
\item
  3b. Semi-supervised usually refers to models where we have some
  labels, and we generate additional labels. Where do our labels come
  from? How do we generate the additional ones?

  \begin{itemize}
  \tightlist
  \item
    The original labels would most likely be generated. As time
    progresses, we get labels back from the users that are interacting
    with our model's recommendations.
  \end{itemize}
\item
  3c. Be more specific: which features would you use which techniques
  on? For example, you could use bag of words or OHE on the names of the
  stars, but you'd get pretty different results depending on which one
  you picked.

  \begin{itemize}
  \tightlist
  \item
    OHE: name of stars, genre. BOW or TFID: title.
  \end{itemize}
\item
  3e. A user not watching a recommendation is not necessarily good
  signal on whether it's a good recommendation (i.e.~I might really like
  a movie, and just not have time to watch it right now). Conversely, a
  user watching a movie is not necessarily signal that it was a good
  recommendation (maybe I watched it because you recommended it, but I
  hated it).

  \begin{itemize}
  \tightlist
  \item
    This depends on the goal of the recommendation. If you get a good
    recommendation and don't watch it, was it really a good
    recommendation? If the goal is simply to increase watch time, and
    thus increase the number of ads viewed, then yes watching or not
    watching is a good metric. Think click-bait. Of course, this has to
    be weighed against the long term effects of the recommendation.
  \end{itemize}
\item
  3f. I know you are kidding (I hope so, at least!), but the whole point
  of us learning about ethics is precisely so that they do not crumble
  in the face of capitalism!

  \begin{itemize}
  \tightlist
  \item
    I think maybe we should shift the goal to rebuilding the already
    crumbled ethics\ldots{}
  \end{itemize}
\item
  4b. Where do these labels come from?

  \begin{itemize}
  \tightlist
  \item
    From the friends you asked.
  \end{itemize}
\item
  4c/d.~Why WPIE/NN? Is there a simpler approach we might try first?

  \begin{itemize}
  \tightlist
  \item
    BOW, TFIDF, or word vectors would work, but Facebook's method itself
    would most likely work better. As for the type of model, Decision
    Trees and Random Forests would work.
  \end{itemize}
\item
  4e. Why not accuracy, precision, or recall?

  \begin{itemize}
  \tightlist
  \item
    Again, just decided to list one validation metric. Accuracy,
    precision, and recall would also work.
  \end{itemize}
\end{itemize}

{[}{[}KBdataProsResponses{]}{]}

\end{document}
